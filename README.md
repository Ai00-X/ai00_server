# ğŸ’¯AI00 RWKV Server

AI00 RWKV Server æ˜¯ä¸€ä¸ªåŸºäº[RWKVæ¨¡å‹](https://github.com/BlinkDL/ChatRWKV)çš„æ¨ç†APIæœåŠ¡å™¨ã€‚

æ”¯æŒVULKANæ¨ç†åŠ é€Ÿï¼Œå¯ä»¥åœ¨æ‰€æœ‰æ”¯æŒVULKANçš„GPUä¸Šè¿è¡Œã€‚

æ— éœ€è‡ƒè‚¿çš„pytorch CUDAç­‰è¿è¡Œç¯å¢ƒï¼Œå°å·§èº«æï¼Œå¼€ç®±å³ç”¨ï¼

å…¼å®¹Openaiçš„ChatGPT APIæ¥å£ã€‚

å¦‚æœæ‚¨æ­£åœ¨å¯»æ‰¾ä¸€ä¸ªå¿«é€Ÿã€é«˜æ•ˆã€æ˜“äºä½¿ç”¨çš„APIæœåŠ¡å™¨ï¼Œé‚£ä¹ˆRWKV API Serveræ˜¯æ‚¨çš„æœ€ä½³é€‰æ‹©ã€‚å®ƒå¯ä»¥ç”¨äºå„ç§ä»»åŠ¡ï¼ŒåŒ…æ‹¬èŠå¤©æœºå™¨äººã€æ–‡æœ¬ç”Ÿæˆã€ç¿»è¯‘å’Œé—®ç­”ã€‚

ç«‹å³åŠ å…¥RWKV API Serverç¤¾åŒºï¼Œä½“éªŒAIçš„é­…åŠ›ï¼

äº¤æµQQç¾¤ï¼š 30920262



AI00 RWKV Server is based on the [RWKV model]ï¼ˆ https://github.com/BlinkDL/ChatRWKV ï¼‰Inference API server for.

Supports VULKAN inference acceleration and can run on all GPUs that support VULKAN.

No need for bulky Pytorch CUDA and other running environments, compact body, ready to use out of the box!

Compatible with Openai's ChatGPT API interface.

If you are looking for a fast, efficient, and easy-to-use API server, then RWKV API Server is your best choice. It can be used for various tasks, including Chatbot, text generation, translation and question answering.

Join the RWKV API Server community now and experience the charm of AI!

## ğŸ’¥ç‰¹è‰² Characteristic

- åŸºäºRWKVæ¨¡å‹ï¼Œå…·æœ‰é«˜æ€§èƒ½å’Œå‡†ç¡®æ€§(Based on the RWKV model, with high performance and accuracy)

- æ”¯æŒVULKANæ¨ç†åŠ é€Ÿï¼Œä¸ç”¨è¯¥æ­»çš„CUDAä¹Ÿèƒ½äº«å—GPUåŠ é€Ÿï¼(Support VULKAN inference acceleration, and enjoy GPU acceleration without the need for damn CUDA!)
- æ— éœ€è‡ƒè‚¿çš„pytorch CUDAç­‰è¿è¡Œç¯å¢ƒï¼Œå°å·§èº«æï¼Œå¼€ç®±å³ç”¨ï¼(No need for bulky Pytorch CUDA and other running environments, compact body, ready to use out of the box!)
- å…¼å®¹Openaiçš„ChatGPT APIæ¥å£(Openai ChatGPT API interface compatible)

## â­•ç”¨é€” Use

- èŠå¤©æœºå™¨äºº   chatbot
- æ–‡æœ¬ç”Ÿæˆ   text generation
- ç¿»è¯‘  translate
- é—®ç­” Q&A
- å…¶ä»–æ‰€æœ‰ä½ èƒ½æƒ³åˆ°çš„LLMèƒ½å¹²çš„äº‹ All the other things LLM can do that you can think of

## ğŸ‘»å…¶ä»– Other

åŸºäº [web-rwkv](https://github.com/cryscan/web-rwkv) é¡¹ç›®

[ä¸‹è½½æ¨¡å‹ ï¼ˆdownload modelsï¼‰](https://huggingface.co/cgisky/RWKV-safetensors-fp16)



------

[^1]: haha



# ğŸ“œ**å®‰è£…** Install

å®‰è£…äº†cargo ç¼–è¯‘ç¯å¢ƒ (Installed the cargo compilation environment)

```bash
git clone https://github.com/cgisky1980/ai00_rwkv_serve.git

cd ai00_rwkv_serve
```
[ä¸‹è½½æ¨¡å‹ ï¼ˆdownload modelsï¼‰](https://huggingface.co/cgisky/RWKV-safetensors-fp16)
æŠŠæ¨¡å‹æ”¾åœ¨ï¼ˆput model file asï¼‰  \assets\models\RWKV-4-World-0.4B-v1-20230529-ctx4096.st
ç›®å‰æ¨¡å‹è·¯å¾„å’Œåç§°å†™æ­»ï¼Œåé¢å¯ä»¥åœ¨å¯åŠ¨å‚æ•°æŒ‡å®š(At present, the model path and name are written dead, and can be specified in the startup parameters later on)

```bash
cargo b -r

./target/release/ai00_server.exe

```

API æœåŠ¡å¼€å¯äº 3000 ç«¯å£(API service is enabled on port 3000)

ç›®å‰å¯ç”¨APIs (Currently available APIs)

/v1/chat/completions

/chat/completions

/v1/completions

/completions