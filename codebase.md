# 代码导读

`Ai00`是一个基于`Axum`的、为`RWKV`模型提供本地推理服务的服务器。这篇文章是它的主要逻辑、代码结构的说明。

## 名词解释
- token: 词元，模型能够处理的、被数字化的最小语言单元。在`RWKV`的词表中，一个`token`通常是一个单词或中文里的一个单字。每个`token`都有它的数字编号，模型的输入输出就是这些数字编号，而不是字符串。 

## Ai00 都做了些甚么
`Ai00`是一个LLM推理服务器。它通过HTTP协议实现了一套API，其他程序通过这套API可以令`Ai00`为它提供的上下文生成一段文字。

逻辑上来说，`Ai00`可以分为前台、中台、后台三个部分：
- 前台: `Axum`服务器，部署着公开的API。那些和模型推理有关的API接受请求后发送给中台。部分和模型推理无关的API（比如直接访问文件系统的API）直接处理并返回。
- 中台: 接受前台API的请求，将请求分拣成模型加载/卸载、模型信息请求、生成文字请求三大类。
  - 中台在接受到模型加载/卸载请求的时候，会创建、销毁后台；
  - 中台在接受生成文字请求的时候，会将各种生成任务整理成统一的续写请求，发送后台处理。
- 后台: 后台拥有着一个模型和一个状态缓存池，而且它只接受中台发来的续写请求。在接受到续写请求后，后台会完成续写，把结果直接发送回前台。

| 模块 | 代码位置                        | 说明                                                                              |
| ---- | ------------------------------- | --------------------------------------------------------------------------------- |
| 前台 | [api](src/api/)                 | 与OpenAI兼容的API在[api/oai](src/api/oai/)里面。                                  |
| 中台 | [middleware](src/middleware.rs) | 入口是`model_route`函数。这个函数运行在一个单独的线程里，时刻监听前台发来的消息。 |
| 后台 | [run](src/run.rs)               | 入口是`run`函数。这个函数持有模型、状态缓存等，也运行在一个单独的线程里。         |

流程图见[这里](Ai00.drawio.html)。

## Ai00 的底层依赖

`Ai00`最重要的依赖是[`web-rwkv`](https://github.com/cryscan/web-rwkv)，它提供了tokenization、载入模型、模型推理的功能，这是整个`Ai00`后端的基础。这里简单介绍以下`web-rwkv`本身提供的功能。

`RWKV`是一个RNN模型。RNN模型在生成文字的时候，接受一串`token`作为**输入**，以及一个蕴含了输入之前所有上下文信息的**状态**，产生一个**概率分布**来预测输入之后下一个词的概率，并同时更新状态。

```rust
let logits = model.run(&mut tokens, &state).await?;
```

上面这个函数就是`web-rwkv`提供的最核心的功能了。我们只要提供了`state`对象和输入文本`tokens`，就帮我们预测下一个词的概率`logits`同时更新`state`的内容。除此之外的琐事`web-rwkv`是不会关心的：比如如何管理多个对话上下文的`state`、如何从输出的概率分布里选出一个词（这叫**采样**）等等，都需要我们（也就是`Ai00`这边）来完成。

> Notes: 这里有人会注意到`tokens`是一个可变引用，`state`是不可变引用。而实际上这个函数执行一次不一定直接返回最后的预测概率，它是每次会“消耗”掉一定数量的输入，如果`tokens`被消耗完了，才会输出概率，否则输出的是`None`。被消耗掉的输入会被从`tokens`中移除，这也是为什么`tokens`是可变引用。而`state`虽然是不可变引用，但其在的GPU显存里的内容是**会被修改**的，只是我们无法在CPU侧体现出它的可变性。
